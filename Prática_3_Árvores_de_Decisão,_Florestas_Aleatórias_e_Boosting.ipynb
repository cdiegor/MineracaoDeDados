{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdiegor/MineracaoDeDados/blob/main/Pr%C3%A1tica_3_%C3%81rvores_de_Decis%C3%A3o%2C_Florestas_Aleat%C3%B3rias_e_Boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92bfb95d",
      "metadata": {
        "id": "92bfb95d"
      },
      "source": [
        "\n",
        "# Laboratório — Árvores de Decisão, Florestas Aleatórias e Boosting\n",
        "**Tópicos:** Árvores (CART), Random Forests, AdaBoost, Gradient Boosting e HistGradientBoosting.  \n",
        "**Foco:** comparação de desempenho, hiperparâmetros essenciais, importância de atributos (Gini e permutação), dependência parcial e *learning curves*.\n",
        "\n",
        "**Datasets:**\n",
        "- **Classificação** — *Breast Cancer Wisconsin* (binário)\n",
        "- **Regressão** — *California Housing* (contínuo)\n",
        "\n",
        "> Objetivo: aplicar e comparar **modelos baseados em árvore**, entendendo *bias–variance*, interpretabilidade e boas práticas de validação.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "49c7230e",
      "metadata": {
        "id": "49c7230e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Preparação ---------------------------------------------------------------\n",
        "# !pip install scikit-learn pandas numpy matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay,\n",
        "    PrecisionRecallDisplay, RocCurveDisplay,\n",
        "    mean_squared_error, r2_score\n",
        ")\n",
        "\n",
        "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
        "\n",
        "np.random.seed(7)\n",
        "plt.rcParams['figure.figsize'] = (7, 4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86452d5d",
      "metadata": {
        "id": "86452d5d"
      },
      "source": [
        "## 1) Carregamento dos dados e *splits*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81aaa00",
      "metadata": {
        "id": "c81aaa00"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Classificação\n",
        "bc = load_breast_cancer(as_frame=True)\n",
        "Xc = bc.data.copy()\n",
        "yc = bc.target.copy()\n",
        "\n",
        "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
        "    Xc, yc, test_size=0.2, stratify=yc, random_state=42\n",
        ")\n",
        "\n",
        "# Regressão\n",
        "house = fetch_california_housing(as_frame=True)\n",
        "Xr = house.data.copy()\n",
        "yr = house.target.copy()\n",
        "\n",
        "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
        "    Xr, yr, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "Xc_train.shape, Xr_train.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0ae00c5",
      "metadata": {
        "id": "d0ae00c5"
      },
      "source": [
        "\n",
        "## 2) Árvores de decisão (CART) — Baselines\n",
        "Vamos começar com **árvores** simples: controlar profundidade, min_samples_leaf e critério (entropia/Gini).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa8b5ad",
      "metadata": {
        "id": "bfa8b5ad"
      },
      "outputs": [],
      "source": [
        "\n",
        "tree_cls = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=5, random_state=7)\n",
        "tree_reg = DecisionTreeRegressor(max_depth=5, min_samples_leaf=5, random_state=7)\n",
        "\n",
        "tree_cls.fit(Xc_train, yc_train)\n",
        "#proba = tree_cls.predict_proba(Xc_test)[:,1]\n",
        "predc = tree_cls.predict(Xc_test)\n",
        "acc_tree = accuracy_score(yc_test, predc)\n",
        "f1_tree = f1_score(yc_test, predc)\n",
        "\n",
        "tree_reg.fit(Xr_train, yr_train)\n",
        "predr = tree_reg.predict(Xr_test)\n",
        "rmse_tree = np.sqrt(mean_squared_error(yr_test, predr))\n",
        "r2_tree = r2_score(yr_test, predr)\n",
        "\n",
        "print(f\"[Classificação] Árvore: AUC={acc_tree:.3f} | F1={f1_tree:.3f}\")\n",
        "print(f\"[Regressão] Árvore: RMSE={rmse_tree:.3f} | R2={r2_tree:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b062c4d6",
      "metadata": {
        "id": "b062c4d6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Visualização parcial da árvore\n",
        "plt.figure(figsize=(10,6))\n",
        "plot_tree(tree_cls, feature_names=Xc.columns, class_names=bc.target_names, filled=True, impurity=False, max_depth=2)\n",
        "plt.title(\"Árvore de Decisão (visão parcial)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98b7e2f",
      "metadata": {
        "id": "d98b7e2f"
      },
      "source": [
        "## 3) Florestas Aleatórias (RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26a2d280",
      "metadata": {
        "id": "26a2d280"
      },
      "outputs": [],
      "source": [
        "\n",
        "rf_cls = RandomForestClassifier(n_estimators=400, max_features='sqrt', oob_score=True, random_state=7, n_jobs=-1)\n",
        "rf_cls.fit(Xc_train, yc_train)\n",
        "predc_rf = rf_cls.predict(Xc_test)\n",
        "acc_rf = accuracy_score(yc_test, predc_rf)\n",
        "print(f\"[Classificação] RF: ACC={acc_rf:.3f} | OOB={rf_cls.oob_score_:.3f}\")\n",
        "\n",
        "rf_reg = RandomForestRegressor(n_estimators=400, max_features='sqrt', random_state=7, n_jobs=-1)\n",
        "rf_reg.fit(Xr_train, yr_train)\n",
        "pred_rf = rf_reg.predict(Xr_test)\n",
        "rmse_rf = np.sqrt(mean_squared_error(yr_test, pred_rf))\n",
        "r2_rf = r2_score(yr_test, pred_rf)\n",
        "print(f\"[Regressão] RF: RMSE={rmse_rf:.3f} | R2={r2_rf:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22d1ebae",
      "metadata": {
        "id": "22d1ebae"
      },
      "source": [
        "### 4) Boosting baseado em árvores — AdaBoost / GradientBoosting / HistGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc6490d",
      "metadata": {
        "id": "1bc6490d"
      },
      "outputs": [],
      "source": [
        "\n",
        "ada = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1, random_state=7),\n",
        "    n_estimators=300, learning_rate=0.5, random_state=7\n",
        ")\n",
        "ada.fit(Xc_train, yc_train)\n",
        "predc_ada = ada.predict(Xc_test)\n",
        "acc_ada = accuracy_score(yc_test, predc_ada)\n",
        "print(f\"AdaBoost (stumps) — ACC teste: {acc_ada:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ce5705",
      "metadata": {
        "id": "c3ce5705"
      },
      "outputs": [],
      "source": [
        "\n",
        "gbc = GradientBoostingClassifier(\n",
        "    n_estimators=300, learning_rate=0.05, max_depth=3, subsample=0.8, random_state=7\n",
        ")\n",
        "gbc.fit(Xc_train, yc_train)\n",
        "predc_gbc = gbc.predict(Xc_test)\n",
        "acc_gbc = roc_auc_score(yc_test, predc_gbc)\n",
        "print(f\"GradientBoostingClassifier — ACC teste: {acc_gbc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74bda580",
      "metadata": {
        "id": "74bda580"
      },
      "outputs": [],
      "source": [
        "\n",
        "gbr = GradientBoostingRegressor(\n",
        "    n_estimators=400, learning_rate=0.05, max_depth=3, subsample=0.8, random_state=7\n",
        ")\n",
        "gbr.fit(Xr_train, yr_train)\n",
        "pred_gbr = gbr.predict(Xr_test)\n",
        "rmse_gbr = np.sqrt(mean_squared_error(yr_test, pred_gbr))\n",
        "r2_gbr = r2_score(yr_test, pred_gbr)\n",
        "print(f\"GradientBoostingRegressor — RMSE={rmse_gbr:.3f} | R2={r2_gbr:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d440d1e",
      "metadata": {
        "id": "4d440d1e"
      },
      "outputs": [],
      "source": [
        "\n",
        "hgbc = HistGradientBoostingClassifier(max_depth=None, learning_rate=0.06, max_iter=300, random_state=7)\n",
        "hgbc.fit(Xc_train, yc_train)\n",
        "predc_hgbc = hgbc.predict(Xc_test)\n",
        "acc_hgbc = roc_auc_score(yc_test, predc_hgbc)\n",
        "print(f\"HistGradientBoostingClassifier — ACC teste: {acc_hgbc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0d2f858",
      "metadata": {
        "id": "a0d2f858"
      },
      "outputs": [],
      "source": [
        "\n",
        "hgbr = HistGradientBoostingRegressor(max_depth=None, learning_rate=0.06, max_iter=400, random_state=7)\n",
        "hgbr.fit(Xr_train, yr_train)\n",
        "pred_hgbr = hgbr.predict(Xr_test)\n",
        "rmse_hgbr = np.sqrt(mean_squared_error(yr_test, pred_hgbr))\n",
        "r2_hgbr = r2_score(yr_test, pred_hgbr)\n",
        "print(f\"HistGradientBoostingRegressor — RMSE={rmse_hgbr:.3f} | R2={r2_hgbr:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c8ce19",
      "metadata": {
        "id": "82c8ce19"
      },
      "source": [
        "## 5) Métricas e curvas (classificação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042a11ca",
      "metadata": {
        "id": "042a11ca"
      },
      "outputs": [],
      "source": [
        "\n",
        "models_cls = {\n",
        "    \"Tree\": (tree_cls, proba),\n",
        "    \"RandomForest\": (rf_cls, proba_rf),\n",
        "    \"AdaBoost\": (ada, ada.predict_proba(Xc_test)[:,1]),\n",
        "    \"GBDT\": (gbc, gbc.predict_proba(Xc_test)[:,1]),\n",
        "    \"HistGB\": (hgbc, hgbc.predict_proba(Xc_test)[:,1])\n",
        "}\n",
        "\n",
        "for name, (m, scores) in models_cls.items():\n",
        "    RocCurveDisplay.from_predictions(yc_test, scores)\n",
        "    plt.title(f\"ROC — {name}\")\n",
        "    plt.show()\n",
        "    PrecisionRecallDisplay.from_predictions(yc_test, scores)\n",
        "    plt.title(f\"Precisão-Revocação — {name}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c88f2710",
      "metadata": {
        "id": "c88f2710"
      },
      "source": [
        "## 6) Curvas de aprendizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48698941",
      "metadata": {
        "id": "48698941"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_learning_curve(model, X, y, cv, scoring=\"roc_auc\", title=\"Curva de Aprendizado\"):\n",
        "    sizes, train_sc, val_sc = learning_curve(model, X, y, cv=cv, scoring=scoring, train_sizes=np.linspace(0.1,1.0,6))\n",
        "    plt.figure()\n",
        "    plt.plot(sizes, train_sc.mean(axis=1), marker='o', label=\"Treino\")\n",
        "    plt.plot(sizes, val_sc.mean(axis=1), marker='s', label=\"Validação\")\n",
        "    plt.xlabel(\"Exemplos de treino\"); plt.ylabel(scoring); plt.title(title)\n",
        "    plt.grid(True); plt.legend(); plt.show()\n",
        "\n",
        "cv_cls = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "plot_learning_curve(rf_cls, Xc, yc, cv=cv_cls, title=\"RF — ROC-AUC\")\n",
        "plot_learning_curve(gbc, Xc, yc, cv=cv_cls, title=\"GBDT — ROC-AUC\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58deb0d9",
      "metadata": {
        "id": "58deb0d9"
      },
      "source": [
        "## 7) Importância de atributos (Gini vs. Entropia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3cdbde4",
      "metadata": {
        "id": "f3cdbde4"
      },
      "outputs": [],
      "source": [
        "\n",
        "imp_gini = pd.Series(rf_cls.feature_importances_, index=Xc.columns).sort_values(ascending=False).head(10)\n",
        "imp_gini\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e252bf",
      "metadata": {
        "id": "41e252bf"
      },
      "outputs": [],
      "source": [
        "\n",
        "rf_cls_entropy = RandomForestClassifier(n_estimators=400, max_features='sqrt', oob_score=True, random_state=7, criterion = \"entropy\", n_jobs=-1)\n",
        "rf_cls_entropy.fit(Xc_train, yc_train)\n",
        "imp_entropy = pd.Series(rf_cls_entropy.feature_importances_, index=Xc.columns).sort_values(ascending=False).head(10)\n",
        "imp_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9db63ede",
      "metadata": {
        "id": "9db63ede"
      },
      "source": [
        "## 8) Dependência parcial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a025261",
      "metadata": {
        "id": "0a025261"
      },
      "outputs": [],
      "source": [
        "\n",
        "feat_top = list(imp_gini.index[:2])\n",
        "fig, ax = plt.subplots(1, len(feat_top), figsize=(10,4))\n",
        "PartialDependenceDisplay.from_estimator(rf_cls, Xc_test, features=feat_top, ax=ax)\n",
        "plt.suptitle(\"Dependência Parcial — RandomForest (dois atributos)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96e28b9a",
      "metadata": {
        "id": "96e28b9a"
      },
      "source": [
        "## 9) Avaliação para regressão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71fa814c",
      "metadata": {
        "id": "71fa814c"
      },
      "outputs": [],
      "source": [
        "\n",
        "for name, pred in {\n",
        "    \"Tree\": predr, \"RF\": pred_rf, \"GBDT\": pred_gbr, \"HistGB\": pred_hgbr\n",
        "}.items():\n",
        "    rmse = np.sqrt(mean_squared_error(yr_test, pred))\n",
        "    r2 = r2_score(yr_test, pred)\n",
        "    print(f\"{name:8s} -> RMSE={rmse:.3f} | R2={r2:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1323dd82",
      "metadata": {
        "id": "1323dd82"
      },
      "source": [
        "## 10) *Mini* Tuning (GridSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "512c2ae8",
      "metadata": {
        "id": "512c2ae8"
      },
      "outputs": [],
      "source": [
        "\n",
        "param = {\n",
        "    \"n_estimators\": [200, 400],\n",
        "    \"max_depth\": [None, 6, 12],\n",
        "    \"max_features\": [\"sqrt\"]\n",
        "}\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "                    param_grid=param, scoring=\"accuracy\", cv=5, n_jobs=-1)\n",
        "grid.fit(Xc_train, yc_train)\n",
        "print(\"Melhor RF:\", grid.best_params_, \"ACC (CV):\", round(grid.best_score_,3))\n",
        "best_rf = grid.best_estimator_\n",
        "test_acc = accuracy_score(yc_test, best_rf.predict(Xc_test))\n",
        "print(\"ACC teste (melhor RF):\", round(test_acc,3))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}