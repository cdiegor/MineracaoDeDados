{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdiegor/MineracaoDeDados/blob/main/Gestos_Rede_Neural_Functional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nbEHr4gRNBAO",
      "metadata": {
        "id": "nbEHr4gRNBAO"
      },
      "source": [
        "# Laboratório — Reconhecimento de Gestos com as Mãos (MediaPipe + Rede Neural, API Functional)\n",
        "\n",
        "Este caderno implementa uma prática **interativa** e **em tempo real** usando **gestos** das mãos (MediaPipe) e uma **Rede Neural** construída com a **API Functional** do Keras.\n",
        "\n",
        "**Fluxo:**\n",
        "\n",
        "1. Coleta de dados com webcam (gestos definidos por você).  \n",
        "2. Extração/normalização de **21×(x,y,z)** landmarks → vetor de **63 features**.  \n",
        "3. Treinamento de uma RN com a API **Functional**.  \n",
        "4. Inferência ao vivo.  \n",
        "5. **Exercícios** no final para os alunos.\n",
        "\n",
        "> **Requisitos locais** (instalar na sua máquina): `mediapipe`, `opencv-python`, `tensorflow` (ou `tensorflow-gpu`), `numpy`, `pandas`, `scikit-learn`, `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TVt1JmkZNBAQ",
      "metadata": {
        "id": "TVt1JmkZNBAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ec9fe4-cf13-4659-9f06-01d3433bbd00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# (Opcional) Instalar pacotes — execute localmente se precisar\n",
        "!pip install mediapipe opencv-python tensorflow pandas scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qIOrpaSuNBAR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIOrpaSuNBAR",
        "outputId": "8aa79300-62b0-4b27-f4cc-9fbca6e3fa7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenCV: 4.11.0\n",
            "MediaPipe: 0.10.21\n",
            "TensorFlow: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "import os, time, json, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2, mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import io\n",
        "import time\n",
        "import base64\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "print(\"OpenCV:\", cv2.__version__)\n",
        "print(\"MediaPipe:\", mp.__version__)\n",
        "print(\"TensorFlow:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OGTKOfMnNBAS",
      "metadata": {
        "id": "OGTKOfMnNBAS"
      },
      "source": [
        "## 1) Parâmetros do projeto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hSI5oFFHNBAS",
      "metadata": {
        "id": "hSI5oFFHNBAS"
      },
      "outputs": [],
      "source": [
        "# ======= CONFIGURAÇÕES =======\n",
        "ROTULOS = [\"pedra\", \"papel\", \"tesoura\"]  # edite aqui\n",
        "AMOSTRAS_POR_ROTULO = 250                # frames a capturar por classe\n",
        "PASTA_SAIDA = Path(\"gestos_dados\")       # onde salvar CSVs e metadados\n",
        "PASTA_SAIDA.mkdir(exist_ok=True)\n",
        "\n",
        "# Nome do arquivo consolidado\n",
        "ARQ_CSV = PASTA_SAIDA / \"gestos_landmarks.csv\"\n",
        "ARQ_META = PASTA_SAIDA / \"meta.json\"\n",
        "\n",
        "# Semente reprodutível\n",
        "SEMENTE = 42\n",
        "np.random.seed(SEMENTE)\n",
        "tf.random.set_seed(SEMENTE)\n",
        "\n",
        "# Exibir janela reduzida para melhorar desempenho\n",
        "LARGURA_FRAME = 960\n",
        "ALTURA_FRAME = 540"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M_aC7QC9NBAS",
      "metadata": {
        "id": "M_aC7QC9NBAS"
      },
      "source": [
        "## 2) Extração & normalização de landmarks\n",
        "\n",
        "- Usamos os **21** pontos do MediaPipe Hands por mão.  \n",
        "- Normalização: centralizamos no punho (landmark 0) e escalamos pela **maior distância** entre pontos (`scale = max(||p_i - p_0||)`), para ficar invariante a escala."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GGxCZHuHNBAS",
      "metadata": {
        "id": "GGxCZHuHNBAS"
      },
      "outputs": [],
      "source": [
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_styles = mp.solutions.drawing_styles\n",
        "\n",
        "def landmarks_para_vetor(landmarks):\n",
        "    \"\"\"Recebe uma lista de 21 landmarks (x,y,z em [0..1] relativos à imagem) e\n",
        "    retorna um vetor 63-D normalizado: centralizado no punho e escalado pelo tamanho da mão.\"\"\"\n",
        "    pts = np.array([[lm.x, lm.y, lm.z] for lm in landmarks], dtype=np.float32)  # shape (21,3)\n",
        "    origem = pts[0].copy()   # punho\n",
        "    pts -= origem            # centraliza\n",
        "    # escala pela maior distância ao punho (evita divisão por zero)\n",
        "    dists = np.linalg.norm(pts, axis=1)\n",
        "    scale = np.max(dists)\n",
        "    if scale < 1e-6:\n",
        "        scale = 1.0\n",
        "    pts /= scale\n",
        "    return pts.flatten()     # 63-D\n",
        "\n",
        "def desenhar_mao(frame, results):\n",
        "    if results.multi_hand_landmarks:\n",
        "        for handLms in results.multi_hand_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame,\n",
        "                handLms,\n",
        "                mp_hands.HAND_CONNECTIONS,\n",
        "                mp_styles.get_default_hand_landmarks_style(),\n",
        "                mp_styles.get_default_hand_connections_style()\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fn_mk9ExNBAT",
      "metadata": {
        "id": "fn_mk9ExNBAT"
      },
      "source": [
        "## 3) Coleta de dados com webcam\n",
        "\n",
        "### Como usar\n",
        "1. Mostre o gesto da classe atual (indicada na janela).  \n",
        "2. Pressione **`c`** para capturar um *lote* de frames (ex.: 10 por vez).  \n",
        "3. Repita até atingir `AMOSTRAS_POR_ROTULO`.  \n",
        "4. Pressione **`n`** para ir ao **próximo rótulo**.  \n",
        "5. Pressione **`q`** para sair a qualquer momento (os dados coletados até então serão salvos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Dg2GoO8eNBAT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "Dg2GoO8eNBAT",
        "outputId": "3a732ef3-63c1-43be-cec2-cb2ac8a7a6dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "\n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "\n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "\n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'Inicializando...';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = 640;\n",
              "      video.height = 480;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia({video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      div.appendChild(imgElement);\n",
              "\n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = '<br><span style=\"color: red; font-weight: bold;\">CLIQUE NO VÍDEO PARA PARAR</span>';\n",
              "      div.appendChild(instruction);\n",
              "\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640;\n",
              "      captureCanvas.height = 480;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label_text) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "\n",
              "      if (labelElement) {\n",
              "        labelElement.innerHTML = label_text;\n",
              "      }\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "      var p = new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      return p;\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PREPARE-SE PARA O GESTO: Aberto ---\n",
            "Posicione a mão. A coleta começará em 3 segundos...\n",
            "\n",
            "--- PREPARE-SE PARA O GESTO: Fechado ---\n",
            "Posicione a mão. A coleta começará em 3 segundos...\n",
            "Coleta finalizada!\n",
            "Salvo dataset_gestos.csv com 100 linhas.\n"
          ]
        }
      ],
      "source": [
        "# 1. Configurações do JavaScript (Webcam no Browser)\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'Inicializando...';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = 640;\n",
        "      video.height = 480;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = '<br><span style=\"color: red; font-weight: bold;\">CLIQUE NO VÍDEO PARA PARAR</span>';\n",
        "      div.appendChild(instruction);\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640;\n",
        "      captureCanvas.height = 480;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label_text) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      if (labelElement) {\n",
        "        labelElement.innerHTML = label_text;\n",
        "      }\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "      var p = new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      return p;\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"Converte a imagem base64 do JS para OpenCV\"\"\"\n",
        "  image_bytes = base64.b64decode(js_reply.split(',')[1])\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "  return img\n",
        "\n",
        "def landmarks_para_vetor(landmarks):\n",
        "    \"\"\"Achata x,y,z de cada ponto em uma lista simples\"\"\"\n",
        "    lista = []\n",
        "    # Agora 'landmarks' será a lista iterável correta\n",
        "    for lm in landmarks:\n",
        "        lista.extend([lm.x, lm.y, lm.z])\n",
        "    return lista\n",
        "\n",
        "# 2. Função de Coleta Principal\n",
        "def coletar_dados_colab(rotulos, amostras_por_rotulo):\n",
        "    video_stream()\n",
        "    label_html = 'Inicializando...'\n",
        "\n",
        "    mp_hands = mp.solutions.hands\n",
        "    todos_registros = []\n",
        "    meta_contagem = {r: 0 for r in rotulos}\n",
        "\n",
        "    with mp_hands.Hands(\n",
        "        static_image_mode=False,\n",
        "        max_num_hands=1,\n",
        "        min_detection_confidence=0.5\n",
        "    ) as hands:\n",
        "\n",
        "        for idx_rotulo, alvo in enumerate(rotulos):\n",
        "            print(f\"\\n--- PREPARE-SE PARA O GESTO: {alvo} ---\")\n",
        "            print(\"Posicione a mão. A coleta começará em 3 segundos...\")\n",
        "            time.sleep(3)\n",
        "\n",
        "            while meta_contagem[alvo] < amostras_por_rotulo:\n",
        "                js_reply = eval_js(f'stream_frame(\"Coletando: {alvo} ({meta_contagem[alvo]}/{amostras_por_rotulo})\")')\n",
        "                if not js_reply:\n",
        "                    print(\"Stream parado pelo usuário.\")\n",
        "                    return todos_registros\n",
        "\n",
        "                frame = js_to_image(js_reply)\n",
        "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame_rgb = cv2.flip(frame_rgb, 1)\n",
        "                results = hands.process(frame_rgb)\n",
        "\n",
        "                if results.multi_hand_landmarks:\n",
        "                    for hand_landmarks in results.multi_hand_landmarks:\n",
        "                        # CORREÇÃO AQUI: Usamos .landmark para pegar a lista de pontos\n",
        "                        vec = landmarks_para_vetor(hand_landmarks.landmark)\n",
        "\n",
        "                        todos_registros.append((vec, alvo))\n",
        "                        meta_contagem[alvo] += 1\n",
        "\n",
        "    print(\"Coleta finalizada!\")\n",
        "    return todos_registros\n",
        "\n",
        "# --- CONFIGURAÇÃO E EXECUÇÃO ---\n",
        "ROTULOS = ['Aberto', 'Fechado']\n",
        "AMOSTRAS_POR_ROTULO = 50\n",
        "\n",
        "dados = coletar_dados_colab(ROTULOS, AMOSTRAS_POR_ROTULO)\n",
        "\n",
        "# Salvar CSV\n",
        "if dados:\n",
        "    X = np.vstack([r[0] for r in dados])\n",
        "    y = np.array([r[1] for r in dados])\n",
        "    df = pd.DataFrame(X)\n",
        "    df['label'] = y\n",
        "    df.to_csv(ARQ_CSV, index=False)\n",
        "    print(f\"Salvo dataset_gestos.csv com {len(df)} linhas.\")\n",
        "else:\n",
        "    print(\"Nenhum dado coletado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wIhYt4meNBAT",
      "metadata": {
        "id": "wIhYt4meNBAT"
      },
      "source": [
        "## 4) Carregar dados coletados e preparar treino\n",
        "Se você já coletou e salvou o CSV (`gestos_dados/gestos_landmarks.csv`), rode a célula abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WRU2PLXkNBAU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRU2PLXkNBAU",
        "outputId": "f682af52-3d66-423e-bfcc-2b516636f762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1             2         3         4         5         6  \\\n",
            "0  0.946732  0.600384  5.162692e-07  0.844764  0.582539 -0.044881  0.755694   \n",
            "1  0.883060  0.479918  6.775433e-07  0.776043  0.382487 -0.030223  0.701869   \n",
            "2  0.897252  0.396865  3.959964e-07  0.793984  0.366610 -0.043226  0.710718   \n",
            "3  0.903695  0.392869  4.036623e-07  0.834517  0.441912 -0.070892  0.773896   \n",
            "4  0.766040  0.942915  7.202541e-07  0.662736  0.889885 -0.051100  0.590900   \n",
            "\n",
            "          7         8         9  ...        54        55        56        57  \\\n",
            "0  0.477344 -0.063750  0.703546  ...  1.037717  0.228479 -0.098734  1.063905   \n",
            "1  0.250155 -0.039040  0.654889  ...  0.982981  0.034354 -0.029423  0.988954   \n",
            "2  0.233629 -0.055470  0.666824  ...  0.979494 -0.005096 -0.025431  0.983383   \n",
            "3  0.431146 -0.117970  0.716971  ...  1.065065  0.248431 -0.115712  1.076796   \n",
            "4  0.771571 -0.081621  0.543393  ...  0.929020  0.562795 -0.163803  0.955752   \n",
            "\n",
            "         58        59        60        61        62   label  \n",
            "0  0.159601 -0.107522  1.086024  0.097115 -0.112591  Aberto  \n",
            "1 -0.027724 -0.032571  0.989518 -0.088276 -0.033767  Aberto  \n",
            "2 -0.026812 -0.018116  0.986032 -0.053323 -0.012555  Aberto  \n",
            "3  0.240947 -0.128273  1.085629  0.231975 -0.137098  Aberto  \n",
            "4  0.481565 -0.185783  0.975152  0.399294 -0.199574  Aberto  \n",
            "\n",
            "[5 rows x 64 columns]\n",
            "Dimensões: (100, 64)\n",
            "Rótulos: ['Aberto', 'Fechado']\n",
            "Distribuição: {'Aberto': 50, 'Fechado': 50}\n"
          ]
        }
      ],
      "source": [
        "assert ARQ_CSV.exists(), f\"Arquivo não encontrado: {ARQ_CSV}. Colete dados com a célula anterior.\"\n",
        "dados = pd.read_csv(ARQ_CSV)\n",
        "print(dados.head())\n",
        "print(\"Dimensões:\", dados.shape)\n",
        "\n",
        "# separar X e y\n",
        "X = dados.drop(columns=[\"label\"]).values.astype(np.float32)\n",
        "labels = dados[\"label\"].values\n",
        "\n",
        "rotulos_unicos = sorted(np.unique(labels).tolist())\n",
        "rotulo2id = {r:i for i,r in enumerate(rotulos_unicos)}\n",
        "y = np.array([rotulo2id[r] for r in labels], dtype=np.int64)\n",
        "\n",
        "print(\"Rótulos:\", rotulos_unicos)\n",
        "print(\"Distribuição:\", pd.Series(labels).value_counts().to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lebPO5DhNBAU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lebPO5DhNBAU",
        "outputId": "ca396b07-dcad-433c-d00c-5246f8c31f05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((80, 63), (20, 63))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=SEMENTE\n",
        ")\n",
        "\n",
        "scaler = StandardScaler().fit(X_tr)\n",
        "X_tr = scaler.transform(X_tr)\n",
        "X_te = scaler.transform(X_te)\n",
        "\n",
        "X_tr.shape, X_te.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "laprZatoNBAV",
      "metadata": {
        "id": "laprZatoNBAV"
      },
      "source": [
        "## 5) Rede Neural (API Functional)\n",
        "\n",
        "Arquitetura simples com **camadas densas** (MLP), **Dropout** e **softmax** final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g7G3T1HaNBAV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "g7G3T1HaNBAV",
        "outputId": "c56a0e51-cb28-4829-9ad1-5daf6937bebc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gestos_mlp_functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gestos_mlp_functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ entrada_63d (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ densa_128 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,192\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop_25 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ densa_64 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop_15 (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ saida_softmax (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ entrada_63d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ densa_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ densa_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ drop_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ saida_softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,578\u001b[0m (64.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,578</span> (64.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,578\u001b[0m (64.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,578</span> (64.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "n_classes = len(rotulos_unicos)\n",
        "\n",
        "entrada = Input(shape=(X_tr.shape[1],), name=\"entrada_63d\")\n",
        "C1 = Dense(128, activation=\"relu\", name=\"densa_128\")(entrada)\n",
        "C2 = Dropout(0.25, name=\"drop_25\")(C1)\n",
        "C3 = Dense(64, activation=\"relu\", name=\"densa_64\")(C2)\n",
        "C4 = Dropout(0.15, name=\"drop_15\")(C3)\n",
        "saida = Dense(n_classes, activation=\"softmax\", name=\"saida_softmax\")(C4)\n",
        "\n",
        "modelo = Model(inputs=entrada, outputs=saida, name=\"gestos_mlp_functional\")\n",
        "modelo.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "modelo.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bC8jy4U0NBAW",
      "metadata": {
        "id": "bC8jy4U0NBAW"
      },
      "source": [
        "## 6) Treino, relatório e matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mUR4tkAyNBAW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mUR4tkAyNBAW",
        "outputId": "a8324cd0-060b-4669-d32b-c84cf26773f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4844 - loss: 1.0609 - val_accuracy: 0.6250 - val_loss: 0.5447 - learning_rate: 0.0010\n",
            "Epoch 2/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.4844 - loss: 0.8887 - val_accuracy: 0.8750 - val_loss: 0.3977 - learning_rate: 0.0010\n",
            "Epoch 3/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.5312 - loss: 0.7617 - val_accuracy: 0.9375 - val_loss: 0.3114 - learning_rate: 0.0010\n",
            "Epoch 4/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5469 - loss: 0.6444 - val_accuracy: 1.0000 - val_loss: 0.2612 - learning_rate: 0.0010\n",
            "Epoch 5/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7656 - loss: 0.5165 - val_accuracy: 1.0000 - val_loss: 0.2282 - learning_rate: 0.0010\n",
            "Epoch 6/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7969 - loss: 0.4664 - val_accuracy: 0.9375 - val_loss: 0.2080 - learning_rate: 0.0010\n",
            "Epoch 7/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9062 - loss: 0.3712 - val_accuracy: 0.9375 - val_loss: 0.1947 - learning_rate: 0.0010\n",
            "Epoch 8/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8750 - loss: 0.3346 - val_accuracy: 0.9375 - val_loss: 0.1842 - learning_rate: 0.0010\n",
            "Epoch 9/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9062 - loss: 0.3080 - val_accuracy: 0.9375 - val_loss: 0.1762 - learning_rate: 0.0010\n",
            "Epoch 10/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8594 - loss: 0.3124 - val_accuracy: 0.9375 - val_loss: 0.1684 - learning_rate: 0.0010\n",
            "Epoch 11/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9219 - loss: 0.2345 - val_accuracy: 0.9375 - val_loss: 0.1595 - learning_rate: 0.0010\n",
            "Epoch 12/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9688 - loss: 0.2220 - val_accuracy: 0.9375 - val_loss: 0.1491 - learning_rate: 0.0010\n",
            "Epoch 13/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9844 - loss: 0.1516 - val_accuracy: 0.9375 - val_loss: 0.1384 - learning_rate: 0.0010\n",
            "Epoch 14/80\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.9844 - loss: 0.1516 - val_accuracy: 0.9375 - val_loss: 0.1280 - learning_rate: 0.0010\n",
            "Acurácia (teste): 0.9000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Aberto       0.83      1.00      0.91        10\n",
            "     Fechado       1.00      0.80      0.89        10\n",
            "\n",
            "    accuracy                           0.90        20\n",
            "   macro avg       0.92      0.90      0.90        20\n",
            "weighted avg       0.92      0.90      0.90        20\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor=\"val_accuracy\", patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-5),\n",
        "    ModelCheckpoint(filepath=str(PASTA_SAIDA / \"melhor_modelo.keras\"),\n",
        "                    monitor=\"val_accuracy\", save_best_only=True)\n",
        "]\n",
        "\n",
        "hist = modelo.fit(\n",
        "    X_tr, y_tr,\n",
        "    epochs=80,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Avaliação em teste\n",
        "te_loss, te_acc = modelo.evaluate(X_te, y_te, verbose=0)\n",
        "print(f\"Acurácia (teste): {te_acc:.4f}\")\n",
        "y_pred = np.argmax(modelo.predict(X_te), axis=1)\n",
        "print(classification_report(y_te, y_pred, target_names=rotulos_unicos))\n",
        "\n",
        "cm = confusion_matrix(y_te, y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=rotulos_unicos)\n",
        "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Matriz de Confusão — Teste\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ahFFzbPKNBAW",
      "metadata": {
        "id": "ahFFzbPKNBAW"
      },
      "source": [
        "## 7) Inferência ao vivo (webcam)\n",
        "\n",
        "Mostre um gesto para a câmera; o modelo predirá em tempo real.  \n",
        "**Teclas:** `q` sai."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var overlayCanvas; // Novo: para desenhar linhas\n",
        "    var ctx;           // Contexto do desenho\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    // Conexões da mão (MediaPipe) para desenhar as linhas\n",
        "    const HAND_CONNECTIONS = [\n",
        "      [0,1],[1,2],[2,3],[3,4],         // Polegar\n",
        "      [0,5],[5,6],[6,7],[7,8],         // Indicador\n",
        "      [5,9],[9,10],[10,11],[11,12],    // Médio\n",
        "      [9,13],[13,14],[14,15],[15,16],  // Anelar\n",
        "      [13,17],[17,18],[18,19],[19,20], // Mínimo\n",
        "      [0,17]                           // Palma\n",
        "    ];\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       overlayCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      div.style.position = 'relative'; // Importante para o overlay\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'Inicializando...';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = 640;\n",
        "      video.height = 480;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      // Criação do Canvas de Overlay (Transparente)\n",
        "      overlayCanvas = document.createElement('canvas');\n",
        "      overlayCanvas.width = 640;\n",
        "      overlayCanvas.height = 480;\n",
        "      overlayCanvas.style.position = 'absolute';\n",
        "      overlayCanvas.style.top = video.offsetTop + 'px';\n",
        "      overlayCanvas.style.left = video.offsetLeft + 'px';\n",
        "      overlayCanvas.style.zIndex = 10;\n",
        "      overlayCanvas.style.pointerEvents = 'none'; // Cliques passam para o vídeo\n",
        "      div.appendChild(overlayCanvas);\n",
        "      ctx = overlayCanvas.getContext('2d');\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = '<br><span style=\"color: red; font-weight: bold;\">CLIQUE NO VÍDEO PARA PARAR</span>';\n",
        "      div.appendChild(instruction);\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640;\n",
        "      captureCanvas.height = 480;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "\n",
        "    async function stream_frame(label_text, landmarks_json) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      if (labelElement) {\n",
        "        labelElement.innerHTML = label_text;\n",
        "      }\n",
        "\n",
        "      // --- LÓGICA DE DESENHO NO BROWSER ---\n",
        "      if (ctx && landmarks_json) {\n",
        "        ctx.clearRect(0, 0, 640, 480); // Limpa desenho anterior\n",
        "        var landmarks = JSON.parse(landmarks_json);\n",
        "\n",
        "        if (landmarks && landmarks.length > 0) {\n",
        "           // Desenhar Linhas (Esqueleto)\n",
        "           ctx.lineWidth = 2;\n",
        "           ctx.strokeStyle = \"#00FF00\"; // Verde\n",
        "           for (let j = 0; j < HAND_CONNECTIONS.length; j++) {\n",
        "              let idx1 = HAND_CONNECTIONS[j][0];\n",
        "              let idx2 = HAND_CONNECTIONS[j][1];\n",
        "              let p1 = landmarks[idx1];\n",
        "              let p2 = landmarks[idx2];\n",
        "              // As coordenadas vêm normalizadas (0 a 1), multiplicar pelo tamanho\n",
        "              ctx.beginPath();\n",
        "              ctx.moveTo(p1.x * 640, p1.y * 480);\n",
        "              ctx.lineTo(p2.x * 640, p2.y * 480);\n",
        "              ctx.stroke();\n",
        "           }\n",
        "\n",
        "           // Desenhar Pontos Vermelhos\n",
        "           ctx.fillStyle = \"#FF0000\";\n",
        "           for (let i = 0; i < landmarks.length; i++) {\n",
        "             let x = landmarks[i].x * 640;\n",
        "             let y = landmarks[i].y * 480;\n",
        "             ctx.beginPath();\n",
        "             ctx.arc(x, y, 4, 0, 2 * Math.PI);\n",
        "             ctx.fill();\n",
        "           }\n",
        "        }\n",
        "      } else if (ctx) {\n",
        "         ctx.clearRect(0, 0, 640, 480); // Limpa se não tiver mão\n",
        "      }\n",
        "      // ------------------------------------\n",
        "\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "      var p = new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      return p;\n",
        "    }\n",
        "    ''')\n",
        "  display(js)"
      ],
      "metadata": {
        "id": "fdeIsBX6829G"
      },
      "id": "fdeIsBX6829G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ZsTrt26NBAX",
      "metadata": {
        "id": "4ZsTrt26NBAX"
      },
      "outputs": [],
      "source": [
        "def inferencia_visual_colab(modelo, scaler, rotulos, conf_min=0.5):\n",
        "    video_stream()\n",
        "\n",
        "    mp_hands = mp.solutions.hands\n",
        "    pred_txt = \"Aguardando gesto...\"\n",
        "    landmarks_json = \"[]\" # Inicialmente vazio\n",
        "\n",
        "    with mp_hands.Hands(\n",
        "        static_image_mode=False,\n",
        "        max_num_hands=1,\n",
        "        min_detection_confidence=0.6,\n",
        "        min_tracking_confidence=0.6\n",
        "    ) as hands:\n",
        "\n",
        "        while True:\n",
        "            # Enviamos texto E os dados dos pontos (JSON) para o JS desenhar\n",
        "            js_reply = eval_js(f'stream_frame(\"{pred_txt}\", \\'{landmarks_json}\\')')\n",
        "\n",
        "            if not js_reply:\n",
        "                print(\"Inferência encerrada.\")\n",
        "                break\n",
        "\n",
        "            frame = js_to_image(js_reply)\n",
        "\n",
        "            # Processamento MediaPipe\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            #frame_rgb = cv2.flip(frame_rgb, 1)\n",
        "            results = hands.process(frame_rgb)\n",
        "\n",
        "            landmarks_json = \"[]\" # Reseta para o próximo frame\n",
        "\n",
        "            if results.multi_hand_landmarks:\n",
        "                # 1. Pega os landmarks\n",
        "                lm_list = results.multi_hand_landmarks[0].landmark\n",
        "\n",
        "                #lm_data = [{'x': 1 - lm.x, 'y': lm.y} for lm in lm_list]\n",
        "\n",
        "                # 2. Prepara os dados para desenhar no JS (Lista de dicts x, y)\n",
        "                # Nota: Não espelhamos x aqui porque o vídeo no HTML já é espelhado se a camera for frontal,\n",
        "                # mas se o desenho sair invertido, altere x para (1 - lm.x)\n",
        "                lm_data = [{'x': lm.x, 'y': lm.y} for lm in lm_list]\n",
        "                landmarks_json = json.dumps(lm_data)\n",
        "\n",
        "                # 3. Prepara vetor para o modelo (Feature Vector)\n",
        "                vec = landmarks_para_vetor(lm_list)\n",
        "                vec_np = np.array(vec).reshape(1, -1)\n",
        "\n",
        "                if scaler:\n",
        "                    vec_np = scaler.transform(vec_np)\n",
        "\n",
        "                # 4. Predição\n",
        "                proba = modelo.predict(vec_np, verbose=0)[0]\n",
        "                k = int(np.argmax(proba))\n",
        "                conf = float(proba[k])\n",
        "\n",
        "                if conf >= conf_min:\n",
        "                    cor = \"green\"\n",
        "                    pred_txt = f\"<span style='color:{cor}'>Pred: {rotulos[k]} ({conf*100:.1f}%)</span>\"\n",
        "                else:\n",
        "                    pred_txt = f\"<span style='color:orange'>Indefinido ({conf*100:.1f}%)</span>\"\n",
        "            else:\n",
        "                pred_txt = \"<span style='color:gray'>Nenhuma mão detectada</span>\"\n",
        "\n",
        "    print(\"Fim.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXECUÇÃO ---\n",
        "print(\"Iniciando inferência com visualização de esqueleto...\")\n",
        "inferencia_visual_colab(modelo, scaler, rotulos_unicos, conf_min=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "2R_5g8nh9FqO",
        "outputId": "e61a32fb-0f7f-4272-84f4-0c2982d2369f"
      },
      "id": "2R_5g8nh9FqO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando inferência com visualização de esqueleto...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var overlayCanvas; // Novo: para desenhar linhas\n",
              "    var ctx;           // Contexto do desenho\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "\n",
              "    // Conexões da mão (MediaPipe) para desenhar as linhas\n",
              "    const HAND_CONNECTIONS = [\n",
              "      [0,1],[1,2],[2,3],[3,4],         // Polegar\n",
              "      [0,5],[5,6],[6,7],[7,8],         // Indicador\n",
              "      [5,9],[9,10],[10,11],[11,12],    // Médio\n",
              "      [9,13],[13,14],[14,15],[15,16],  // Anelar\n",
              "      [13,17],[17,18],[18,19],[19,20], // Mínimo\n",
              "      [0,17]                           // Palma\n",
              "    ];\n",
              "\n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       overlayCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "\n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "\n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      div.style.position = 'relative'; // Importante para o overlay\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'Inicializando...';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = 640;\n",
              "      video.height = 480;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia({video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      // Criação do Canvas de Overlay (Transparente)\n",
              "      overlayCanvas = document.createElement('canvas');\n",
              "      overlayCanvas.width = 640;\n",
              "      overlayCanvas.height = 480;\n",
              "      overlayCanvas.style.position = 'absolute';\n",
              "      overlayCanvas.style.top = video.offsetTop + 'px';\n",
              "      overlayCanvas.style.left = video.offsetLeft + 'px';\n",
              "      overlayCanvas.style.zIndex = 10;\n",
              "      overlayCanvas.style.pointerEvents = 'none'; // Cliques passam para o vídeo\n",
              "      div.appendChild(overlayCanvas);\n",
              "      ctx = overlayCanvas.getContext('2d');\n",
              "\n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = '<br><span style=\"color: red; font-weight: bold;\">CLIQUE NO VÍDEO PARA PARAR</span>';\n",
              "      div.appendChild(instruction);\n",
              "\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640;\n",
              "      captureCanvas.height = 480;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "      return stream;\n",
              "    }\n",
              "\n",
              "    async function stream_frame(label_text, landmarks_json) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "\n",
              "      if (labelElement) {\n",
              "        labelElement.innerHTML = label_text;\n",
              "      }\n",
              "\n",
              "      // --- LÓGICA DE DESENHO NO BROWSER ---\n",
              "      if (ctx && landmarks_json) {\n",
              "        ctx.clearRect(0, 0, 640, 480); // Limpa desenho anterior\n",
              "        var landmarks = JSON.parse(landmarks_json);\n",
              "\n",
              "        if (landmarks && landmarks.length > 0) {\n",
              "           // Desenhar Linhas (Esqueleto)\n",
              "           ctx.lineWidth = 2;\n",
              "           ctx.strokeStyle = \"#00FF00\"; // Verde\n",
              "           for (let j = 0; j < HAND_CONNECTIONS.length; j++) {\n",
              "              let idx1 = HAND_CONNECTIONS[j][0];\n",
              "              let idx2 = HAND_CONNECTIONS[j][1];\n",
              "              let p1 = landmarks[idx1];\n",
              "              let p2 = landmarks[idx2];\n",
              "              // As coordenadas vêm normalizadas (0 a 1), multiplicar pelo tamanho\n",
              "              ctx.beginPath();\n",
              "              ctx.moveTo(p1.x * 640, p1.y * 480);\n",
              "              ctx.lineTo(p2.x * 640, p2.y * 480);\n",
              "              ctx.stroke();\n",
              "           }\n",
              "\n",
              "           // Desenhar Pontos Vermelhos\n",
              "           ctx.fillStyle = \"#FF0000\";\n",
              "           for (let i = 0; i < landmarks.length; i++) {\n",
              "             let x = landmarks[i].x * 640;\n",
              "             let y = landmarks[i].y * 480;\n",
              "             ctx.beginPath();\n",
              "             ctx.arc(x, y, 4, 0, 2 * Math.PI);\n",
              "             ctx.fill();\n",
              "           }\n",
              "        }\n",
              "      } else if (ctx) {\n",
              "         ctx.clearRect(0, 0, 640, 480); // Limpa se não tiver mão\n",
              "      }\n",
              "      // ------------------------------------\n",
              "\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "      var p = new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      return p;\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferência encerrada.\n",
            "Fim.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ekspwV1LNBAX",
      "metadata": {
        "id": "ekspwV1LNBAX"
      },
      "source": [
        "---\n",
        "## 8) Exercícios propostos\n",
        "\n",
        "1. **Novo gesto**: adicione um rótulo (ex.: `joinha`) e **recolete** dados. Atualize `ROTULOS` e refaça o treino.  \n",
        "2. **Robustez**: varie iluminação, distância e posição. Meça queda de acurácia e discuta estratégias (mais dados, *augmentation* geométrica nos landmarks, regularização).  \n",
        "3. **Arquitetura**: modifique a rede (camadas, neurônios, *dropout*). Compare no conjunto de teste.  \n",
        "4. **Threshold**: ajuste `conf_min` na inferência para reduzir falsos positivos. Plote acurácia vs. threshold.  \n",
        "5. **Cross-user**: colete dados de 2–3 pessoas e avalie generalização com *GroupKFold* (agrupando por pessoa).  \n",
        "6. **Feature engineering**: além de `(x,y,z)` normalizados, acrescente **distâncias** ou **ângulos** entre pontos (ex.: distância entre ponta do indicador e polegar). Veja se melhora.  \n",
        "7. **Latência**: meça FPS com e sem desenhar landmarks (use `time.time()`), relate impacto no desempenho.  \n",
        "8. **Multi-mão** (avançado): habilite `max_num_hands=2` e crie rótulos que dependem de duas mãos simultâneas (ex.: “duplo joinha”).  \n",
        "9. **Salvar/Carregar**: salve `melhor_modelo.keras` e o `StandardScaler` (pickle) e crie um script só de inferência.  \n",
        "10. **Comparação**: treine um **SVM** (sklearn) com as mesmas features e compare com a RN (accuracy e matriz de confusão)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}