{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdiegor/MineracaoDeDados/blob/main/Pr%C3%A1tica_1_Introdu%C3%A7%C3%A3o_%C3%A0_Minera%C3%A7%C3%A3o_de_Dados_Fluxo_e_Valida%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f0767b2",
      "metadata": {
        "id": "1f0767b2"
      },
      "source": [
        "\n",
        "# Prática 1 - Fluxo de trabalho e validação de modelos\n",
        "\n",
        "**Disciplina:** Introdução à Mineração de Dados  \n",
        "**Foco da prática:** Entradas/saídas, ciclo de dados, particionamento (treino/validação/teste), métricas de avaliação, validação cruzada, curvas de aprendizado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c767fa",
      "metadata": {
        "id": "29c767fa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Preparação ------------------------------------------------------------------\n",
        "# Se necessário, instale scikit-learn (em muitos ambientes educacionais já está instalado).\n",
        "# !pip install scikit-learn pandas numpy matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, ConfusionMatrixDisplay,\n",
        "    RocCurveDisplay, PrecisionRecallDisplay,\n",
        "    mean_squared_error, r2_score, brier_score_loss\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "np.random.seed(7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd2a54b",
      "metadata": {
        "id": "7bd2a54b"
      },
      "source": [
        "\n",
        "## 1. Fluxo de ML & divisões de dados\n",
        "\n",
        "**Etapas típicas**: formulação do problema → coleta/limpeza/EDA → engenharia de atributos → modelagem → avaliação & validação → seleção → implantação/monitoramento.\n",
        "\n",
        "**Divisões**:\n",
        "- **Treino**: ajustar modelos e fazer tuning de hiperparâmetros (com CV no conjunto de treino).\n",
        "- **Validação**: (opcional quando não se usa CV) seleção preliminar de modelos; em CV aninhada, o laço interno decide.\n",
        "- **Teste**: uso **único** ao final, para estimativa imparcial.\n",
        "\n",
        "> **Regra de ouro**: Nunca usar o conjunto de teste para tomar decisões de modelo/atributos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "955d9929",
      "metadata": {
        "id": "955d9929"
      },
      "source": [
        "\n",
        "## 2. Demonstração de classificação — Baseline, métricas e validação cruzada\n",
        "\n",
        "Usaremos o conjunto **Breast Cancer Wisconsin** (classificação binária).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73eca452",
      "metadata": {
        "id": "73eca452"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Carregar dados\n",
        "data = load_breast_cancer(as_frame=True)\n",
        "X = data.data\n",
        "y = pd.Series(data.target, name=\"alvo\")\n",
        "X.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967cd91a",
      "metadata": {
        "id": "967cd91a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split treino/teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(X_train.shape, X_test.shape)\n",
        "y_train.value_counts(normalize=True).round(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2c4b54c",
      "metadata": {
        "id": "e2c4b54c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Modelo baseline: Regressão Logística com padronização\n",
        "pipe_lr = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "# Validação cruzada no conjunto de treino\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(pipe_lr, X_train, y_train, cv=cv, scoring=\"roc_auc\")\n",
        "print(\"CV ROC-AUC:\", np.round(cv_scores, 4), \"Média:\", cv_scores.mean().round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae030e21",
      "metadata": {
        "id": "ae030e21"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ajustar e avaliar no conjunto de teste\n",
        "pipe_lr.fit(X_train, y_train)\n",
        "proba = pipe_lr.predict_proba(X_test)[:, 1]\n",
        "pred = (proba >= 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, pred)\n",
        "prec = precision_score(y_test, pred)\n",
        "rec = recall_score(y_test, pred)\n",
        "f1 = f1_score(y_test, pred)\n",
        "auc = roc_auc_score(y_test, proba)\n",
        "\n",
        "print(f\"Teste -> Acurácia={acc:.3f}  Precisão={prec:.3f}  Revocação={rec:.3f}  F1={f1:.3f}  ROC-AUC={auc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddf074ca",
      "metadata": {
        "id": "ddf074ca"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Matriz de confusão e curvas ROC/PR\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.title(\"Matriz de Confusão (limiar=0.5)\")\n",
        "plt.show()\n",
        "\n",
        "RocCurveDisplay.from_predictions(y_test, proba)\n",
        "plt.title(\"Curva ROC\")\n",
        "plt.show()\n",
        "\n",
        "PrecisionRecallDisplay.from_predictions(y_test, proba)\n",
        "plt.title(\"Curva Precisão-Revocação\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8388982a",
      "metadata": {
        "id": "8388982a"
      },
      "source": [
        "\n",
        "## 3. Curvas de aprendizado & intuição viés–variância\n",
        "\n",
        "Curvas de aprendizado mostram o desempenho de treino e de validação em função do tamanho do conjunto de treino.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c1fb02",
      "metadata": {
        "id": "d9c1fb02"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_sizes, train_scores, valid_scores = learning_curve(\n",
        "    pipe_lr, X_train, y_train, cv=cv, scoring=\"roc_auc\", train_sizes=np.linspace(0.1, 1.0, 6), n_jobs=None\n",
        ")\n",
        "\n",
        "train_mean = train_scores.mean(axis=1)\n",
        "valid_mean = valid_scores.mean(axis=1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_sizes, train_mean, marker='o', label=\"ROC-AUC Treino\")\n",
        "plt.plot(train_sizes, valid_mean, marker='s', label=\"ROC-AUC Validação (CV)\")\n",
        "plt.xlabel(\"Exemplos de treino\")\n",
        "plt.ylabel(\"Pontuação\")\n",
        "plt.title(\"Curva de Aprendizado (Reg. Logística)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77b8224f",
      "metadata": {
        "id": "77b8224f"
      },
      "source": [
        "\n",
        "## 4. Calibração de probabilidades\n",
        "\n",
        "Boas probabilidades são úteis (ajuste de limiares, decisões custo-sensíveis). Vamos inspecionar o **gráfico de calibração** e o **Brier score**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1a7c7f",
      "metadata": {
        "id": "5e1a7c7f"
      },
      "outputs": [],
      "source": [
        "\n",
        "prob_true, prob_pred = calibration_curve(y_test, proba, n_bins=10, strategy=\"quantile\")\n",
        "brier = brier_score_loss(y_test, proba)\n",
        "print(f\"Brier score = {brier:.4f} (menor é melhor)\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(prob_pred, prob_true, marker='o', label=\"Modelo\")\n",
        "plt.plot([0,1], [0,1], linestyle='--', label=\"Perfeitamente calibrado\")\n",
        "plt.xlabel(\"Probabilidade prevista\")\n",
        "plt.ylabel(\"Frequência observada\")\n",
        "plt.title(\"Curva de Calibração\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ec33e30",
      "metadata": {
        "id": "6ec33e30"
      },
      "source": [
        "\n",
        "## 5. Desbalanceamento de classes & limiares\n",
        "\n",
        "Desbalanceamento afeta as métricas. Vamos simular um desbalanceamento mais forte reduzindo a classe positiva no treino e comparar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab19db30",
      "metadata": {
        "id": "ab19db30"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Treino desbalanceado (apenas para demonstração)\n",
        "X_tr_imb, y_tr_imb = X_train.copy(), y_train.copy()\n",
        "pos_idx = y_tr_imb[y_tr_imb == 1].index\n",
        "keep_pos = np.random.choice(pos_idx, size=max(10, len(pos_idx)//5), replace=False)\n",
        "mask = y_tr_imb.index.isin(keep_pos) | (y_tr_imb == 0)\n",
        "X_tr_imb = X_tr_imb.loc[mask]\n",
        "y_tr_imb = y_tr_imb.loc[mask]\n",
        "\n",
        "pipe_lr_imb = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", LogisticRegression(max_iter=200, class_weight=None))])\n",
        "pipe_lr_imb.fit(X_tr_imb, y_tr_imb)\n",
        "proba_imb = pipe_lr_imb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"AUC do modelo padrão:\", roc_auc_score(y_test, proba))\n",
        "print(\"AUC do modelo treinado desbalanceado:\", roc_auc_score(y_test, proba_imb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7359efaa",
      "metadata": {
        "id": "7359efaa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Exemplo de ajuste de limiar no modelo padrão\n",
        "thresholds = np.linspace(0.1, 0.9, 9)\n",
        "records = []\n",
        "for thr in thresholds:\n",
        "    pred_thr = (proba >= thr).astype(int)\n",
        "    records.append({\n",
        "        \"limiar\": thr,\n",
        "        \"precisao\": precision_score(y_test, pred_thr),\n",
        "        \"revocacao\": recall_score(y_test, pred_thr),\n",
        "        \"f1\": f1_score(y_test, pred_thr)\n",
        "    })\n",
        "\n",
        "thr_df = pd.DataFrame(records)\n",
        "thr_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdf0e6b9",
      "metadata": {
        "id": "fdf0e6b9"
      },
      "source": [
        "\n",
        "## 6. Mini-demo de regressão — Métricas e validação\n",
        "\n",
        "Usaremos **California Housing** para ilustrar métricas de regressão e validação.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9d566f",
      "metadata": {
        "id": "3a9d566f"
      },
      "outputs": [],
      "source": [
        "\n",
        "house = fetch_california_housing(as_frame=True)\n",
        "Xr = house.data\n",
        "yr = house.target\n",
        "\n",
        "Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.2, random_state=42)\n",
        "\n",
        "pipe_lin = Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"reg\", LinearRegression())])\n",
        "# with_mean=False evita problemas caso matrizes esparsas sejam usadas (aqui é denso).\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_mse = -cross_val_score(pipe_lin, Xr_train, yr_train, cv=kfold, scoring=\"neg_mean_squared_error\")\n",
        "print(\"CV RMSE:\", np.sqrt(cv_mse).round(3), \"Média:\", np.sqrt(cv_mse.mean()).round(3))\n",
        "\n",
        "pipe_lin.fit(Xr_train, yr_train)\n",
        "pred_r = pipe_lin.predict(Xr_test)\n",
        "rmse = np.sqrt(mean_squared_error(yr_test, pred_r))\n",
        "r2 = r2_score(yr_test, pred_r)\n",
        "print(f\"Teste -> RMSE={rmse:.3f}  R2={r2:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91537c89",
      "metadata": {
        "id": "91537c89"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Gráfico de resíduos\n",
        "resid = yr_test - pred_r\n",
        "plt.figure()\n",
        "plt.scatter(pred_r, resid, alpha=0.6)\n",
        "plt.axhline(0, linestyle='--')\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Resíduo (y - y_hat)\")\n",
        "plt.title(\"Gráfico de Resíduos\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60c69dd2",
      "metadata": {
        "id": "60c69dd2"
      },
      "source": [
        "\n",
        "## 7. Um fluxo mínimo de análise de erros\n",
        "\n",
        "1) Escolha uma métrica-alvo clara.  \n",
        "2) Fatie o desempenho por coortes relevantes (ex.: tamanho, região, tempo).  \n",
        "3) Inspecione exemplos de alto erro (FP/FN).  \n",
        "4) Hipotetize atributos/transformações úteis; rode pequenas modificações.  \n",
        "5) Documente o que funcionou e o que não funcionou (reprodutibilidade).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}